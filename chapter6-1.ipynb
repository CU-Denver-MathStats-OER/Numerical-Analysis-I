{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64730ae5",
   "metadata": {},
   "source": [
    "# 6.1 Discrete least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2176d41f",
   "metadata": {},
   "source": [
    "## Arya's adventures in the physics lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc9bae",
   "metadata": {},
   "source": [
    "College life is expensive, and Arya is happy to land a job working at a physics lab for some extra cash. She does some experiments, some data analysis, and a little grading. In one experiment she conducted, where there is one independent variable $x$, and one dependent variable $y$, she was asked to plot $y$ against $x$ values. (There are a total of six data points.) She gets the following plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745020e2",
   "metadata": {},
   "source": [
    "<img src=\"./images/scatter_plot.png\" class=\"bg-primary mb-1\" width=\"400px\">\n",
    "\n",
    "Scatter plot of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077503ca",
   "metadata": {},
   "source": [
    "Arya's professor thinks the relationship between the variables should be\n",
    "linear, but we do not see data falling on a perfect line because of\n",
    "measurement error. The professor is not happy, professors are usually not happy when lab results act up, and asks Arya to come up with a linear formula,\n",
    "something like $y=ax+b,$ to explain the relationship. Arya first thinks about interpolation, but quickly realizes it is not a good idea. (Why?) Let's help Arya with her problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88ef83",
   "metadata": {},
   "source": [
    "## Analysis of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2179ca1",
   "metadata": {},
   "source": [
    "Let's try passing a line through the data points. The following figure\n",
    "plots one such line, $y=3x-0.5$, together with the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d75235",
   "metadata": {},
   "source": [
    "<img src=\"./images/scatter_plot_line.png\" class=\"bg-primary mb-1\" width=\"400px\">\n",
    "\n",
    "Data with an approximating line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03800b90",
   "metadata": {},
   "source": [
    "There are certainly many other choices we have for the line: we could increase or decrease the slope a little, change the intercept a bit, and obtain multiple lines that have a visually good fit to the data. The crucial question is, how can we decide which line is the \"best\" line, among all the possible lines? If we can quantify how good the fit of a given line is to the data, and come up with a notion for error, perhaps then we can find the line that minimizes this error.\n",
    "\n",
    "Let's generalize the problem a little. We have:\n",
    "\n",
    "- Data: $(x_{1},y_{1}),(x_{2},y_{2}),\\ldots,(x_{m},y_{m})$\n",
    "\n",
    "and we want to find a line that give the \"best\" approximation to the data:\n",
    "\n",
    "- Linear approximation: $y=f(x)=ax+b$\n",
    "\n",
    "The questions we want to answer are:\n",
    "\n",
    "1. What does \"best\" approximation mean?\n",
    "2. How do we find $a,b$ that gives the line with the \"best\" approximation?\n",
    "\n",
    "Observe that for each $x_{i}$, there is the corresponding $y_{i}$\n",
    "of the data point, and $f(x_{i})=ax_{i}+b,$ which is the predicted\n",
    "value by the linear approximation. We can measure error by considering\n",
    "the deviations between the actual $y$ coordinates and the predicted\n",
    "values:\n",
    "\\begin{equation*}\n",
    "(y_{1}-ax_{1}-b),(y_{2}-ax_{2}-b),\\ldots,(y_{m}-ax_{m}-b).\n",
    "\\end{equation*}\n",
    "There are several ways we can form a measure of error using these\n",
    "deviations, and each approach gives a different line approximating the data. The best approximation means finding\n",
    "$a,b$ that minimize the error measured in one of the following ways:\n",
    "\n",
    "- $E=\\max_{i}\\left\\{ |y_{i}-ax_{i}-b|\\right\\} $ ; minimax problem\n",
    "- $E=\\sum_{i=1}^{m}|y_{i}-ax_{i}-b|$; absolute deviations\n",
    "- $E=\\sum_{i=1}^{m}(y_{i}-ax_{i}-b)^{2}$; least squares problem\n",
    "\n",
    "In this chapter we will discuss the least squares problem, the simplest\n",
    "one among the three options. We want to minimize\n",
    "\\begin{equation*}\n",
    "E=\\sum_{i=1}^{m}(y_{i}-ax_{i}-b)^{2}\n",
    "\\end{equation*}\n",
    "with respect to the parameters $a,b.$ For a minimum to occur, we\n",
    "must have\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial E}{\\partial a}=0\\text{ and }\\frac{\\partial E}{\\partial b}=0.\n",
    "\\end{equation*}\n",
    "We have:\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial a} & =\\sum_{i=1}^{m}\\frac{\\partial (y_{i}-ax_{i}-b)^{2}}{\\partial a}=\\sum_{i=1}^{m}(-2x_{i})(y_{i}-ax_{i}-b)=0\\\\\n",
    "\\frac{\\partial E}{\\partial b} & =\\sum_{i=1}^{m}\\frac{\\partial (y_{i}-ax_{i}-b)^{2}}{\\partial b}=\\sum_{i=1}^{m}(-2)(y_{i}-ax_{i}-b)=0.\n",
    "\\end{align*}\n",
    "Using algebra, these equations can be simplified as\n",
    "\\begin{align*}\n",
    "b\\sum_{i=1}^{m}x_{i}+a\\sum_{i=1}^{m}x_{i}^{2} & =\\sum_{i=1}^{m}x_{i}y_{i}\\\\\n",
    "bm+a\\sum_{i=1}^{m}x_{i} & =\\sum_{i=1}^{m}y_{i},\n",
    "\\end{align*}\n",
    "which are called the **normal equations**. The solution to this system\n",
    "of equations is\n",
    "\\begin{align*}\n",
    "a  =\\frac{m\\sum_{i=1}^{m}x_{i}y_{i}-\\sum_{i=1}^{m}x_{i}\\sum_{i=1}^{m}y_{i}}{m\\left(\\sum_{i=1}^{m}x_{i}^{2}\\right)-\\left(\\sum_{i=1}^{m}x_{i}\\right)^{2}},\n",
    "b  =\\frac{\\sum_{i=1}^{m}x_{i}^{2}\\sum_{i=1}^{m}y_{i}-\\sum_{i=1}^{m}x_{i}y_{i}\\sum_{i=1}^{m}x_{i}}{m\\left(\\sum_{i=1}^{m}x_{i}^{2}\\right)-\\left(\\sum_{i=1}^{m}x_{i}\\right)^{2}}.\n",
    "\\end{align*}\n",
    "\n",
    "Let's consider a slightly more general question. Given data\n",
    "\n",
    "- Data: $(x_{1},y_{1}),(x_{2},y_{2}),\\ldots,(x_{m},y_{m})$\n",
    "\n",
    "can we find the best polynomial approximation\n",
    "\n",
    "- Polynomial approximation: $P_{n}(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+\\cdots+a_{0}$\n",
    "\n",
    "where $m$ will be usually much larger than $n$.\n",
    "Similar to the above discussion, we want to minimize\n",
    "\\begin{equation*}\n",
    "E=\\sum_{i=1}^{m}(y_{i}-P_{n}(x_{i}))^{2}=\\sum_{i=1}^{m}\\left(y_{i}-\\sum_{j=0}^{n}a_{j}x_{i}^{j}\\right)^{2}\n",
    "\\end{equation*}\n",
    "with respect to the parameters $a_{n},a_{n-1},\\ldots,a_{0}$. For a minimum\n",
    "to occur, the necessary conditions are\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial E}{\\partial a_{k}}=0\\Rightarrow-\\sum_{i=1}^{m}y_{i}x_{i}^{k}+\\sum_{j=0}^{n}a_{j}\\left(\\sum_{i=1}^{m}x_{i}^{k+j}\\right)=0\n",
    "\\end{equation*}\n",
    "for $k=0,1,\\ldots,n$. (we are skipping some algebra here!) The **normal\n",
    "equations** for polynomial approximation are\n",
    "\n",
    "\\begin{equation}\\label{eq:discrete_normal}\n",
    "\\sum_{j=0}^{n}a_{j}\\left(\\sum_{i=1}^{m}x_{i}^{k+j}\\right)=\\sum_{i=1}^{m}y_{i}x_{i}^{k}\n",
    "\\end{equation}\n",
    "\n",
    "for $k=0,1,\\ldots,n.$ This is a system of $(n+1)$ equations and $(n+1)$\n",
    "unknowns. We can write this system as a matrix equation\n",
    "\n",
    "\\begin{equation}\\label{eq:leastsqmatrixeq}\n",
    "A\\boldsymbol{a}=\\boldsymbol{b}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\boldsymbol{a}$ is the unknown vector we are trying to find, and $\\boldsymbol{b}$ is the constant vector\n",
    "\\begin{equation*}\n",
    "\\boldsymbol{a}=\\begin{bmatrix}\n",
    "a_0\\\\\n",
    "a_1\\\\\n",
    "\\vdots \\\\\n",
    "a_n\n",
    "\\end{bmatrix},\n",
    "\\boldsymbol{b}=\\begin{bmatrix}\n",
    "\\sum_{i=1}^{m}y_{i}\\\\\n",
    "\\sum_{i=1}^{m}y_{i}x_{i}\\\\\n",
    "\\vdots\\\\\n",
    "\\sum_{i=1}^{m}y_{i}x_{i}^{n}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "and $A$ is an $(n+1)$ by $(n+1)$ symmetric matrix with $(k,j)$th entry $A_{kj}, k=1,\\ldots,n+1, j=1,2,...,n+1$ given by\n",
    "\\begin{equation*}\n",
    "A_{kj}=\\sum_{i=1}^m x_i^{k+j-2}.\n",
    "\\end{equation*}\n",
    "The equation $A\\boldsymbol{a}=\\boldsymbol{b}$ has a unique solution if the $x_{i}$ are distinct, and $n\\leq m-1$. Solving this equation by computing the inverse matrix $A^{-1}$ is not advisable, since there could be significant roundoff error. Next, we will write a Python code for least squares approximation, and use the Python function $np.linalg.solve(A, b)$ to solve the matrix equation $A\\boldsymbol{a}=\\boldsymbol{b}$ for $\\boldsymbol{a}$. The $np.linalg.solve$ function in Python uses numerically optimized matrix factorizations based on the LAPACK routine to solve the matrix equation. More details on this topic can be found in Heath [1997] (Chapter 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dc58d",
   "metadata": {},
   "source": [
    "## Python code for least squares approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ae2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3810912",
   "metadata": {},
   "source": [
    "The function **leastsqfit** takes the $x$- and\n",
    "$y$-coordinates of the data, and the degree of the polynomial we want\n",
    "to use, $n$, as inputs. It solves the matrix Equation \\eqref{eq:leastsqmatrixeq}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastsqfit(x, y, n):\n",
    "    m = x.size # number of data points\n",
    "    d = n+1 # number of coefficients to be determined\n",
    "    A = np.zeros((d, d))\n",
    "    b = np.zeros(d)\n",
    "    # the linear system we want to solve is Ax=b\n",
    "    p = np.zeros(2*n+1)\n",
    "    for k in range(d):\n",
    "        sum = 0\n",
    "        for i in range(m):\n",
    "            sum += y[i]*x[i]**k\n",
    "        b[k] = sum\n",
    "    # p[i] below is the sum of the ith power of the x coordinates\n",
    "    p[0] = m\n",
    "    for i in range(1, 2*n+1):\n",
    "        sum = 0\n",
    "        for j in range(m):\n",
    "            sum += x[j]**i\n",
    "        p[i] = sum    \n",
    "    # We next compute the upper triangular part of the coefficient\n",
    "    # matrix A, and its diagonal\n",
    "    for k in range(d):\n",
    "        for j in range(k, d):\n",
    "            A[k, j] = p[k+j]\n",
    "    # The lower triangular part of the matrix is defined using the\n",
    "    # fact the matrix is symmetric\n",
    "    for i in range(1, d):\n",
    "        for j in range(i):\n",
    "            A[i, j] = A[j, i]\n",
    "    a = np.linalg.solve(A, b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686770c",
   "metadata": {},
   "source": [
    "Here is the data used to produce the first plot of the chapter: Arya's\n",
    "data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = np.array([1, 2, 3, 4, 5, 6])\n",
    "yd = np.array([3, 5, 9.2, 11, 14.5, 19])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8736a7",
   "metadata": {},
   "source": [
    "We fit a least squares line to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2af332",
   "metadata": {},
   "outputs": [],
   "source": [
    "leastsqfit(xd, yd, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c508bf",
   "metadata": {},
   "source": [
    "The polynomial is $-0.746667+3.15143x$. The next function\n",
    "**poly(x,a)** takes the output of $a=$**leastsqfit**,\n",
    "and evaluates the least squares polynomial at $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dbe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x, a):\n",
    "    d = a.size\n",
    "    sum = 0\n",
    "    for i in range(d):\n",
    "        sum += a[i]*x**i\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b534da",
   "metadata": {},
   "source": [
    "For example, if we want to compute the least squares line at 3.5, we\n",
    "call the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 1)\n",
    "poly(3.5, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111bd0e",
   "metadata": {},
   "source": [
    "The next function computes the least squares error:\n",
    "$E=\\sum_{i=1}^m(y_i-p_n(x_i))^2$. It takes the output of\n",
    "$a=$**leastsqfit**, and the data, as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86610ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leastsqerror(a, x, y):\n",
    "    sum = 0\n",
    "    m = y.size\n",
    "    for i in range(m):\n",
    "        sum += (y[i]-poly(x[i],a))**2\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 1)\n",
    "leastsqerror(a, xd, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc3b38",
   "metadata": {},
   "source": [
    "Next we plot the least squares line and the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2fa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 1)\n",
    "xaxis = np.linspace(1, 6, 500)\n",
    "yvals = poly(xaxis, a)\n",
    "plt.plot(xaxis, yvals)\n",
    "plt.plot(xd, yd, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee6c110",
   "metadata": {},
   "source": [
    "We try a second degree polynomial in least squares approximation next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd668c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 2)\n",
    "xaxis = np.linspace(1, 6, 500)\n",
    "yvals = poly(xaxis, a)\n",
    "plt.plot(xaxis, yvals)\n",
    "plt.plot(xd, yd, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c04633",
   "metadata": {},
   "source": [
    "The corresponding error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "leastsqerror(a, xd, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bd4c9",
   "metadata": {},
   "source": [
    "The next polynomial is of degree three:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 3)\n",
    "xaxis = np.linspace(1, 6, 500)\n",
    "yvals = poly(xaxis, a)\n",
    "plt.plot(xaxis, yvals)\n",
    "plt.plot(xd, yd, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d785b3",
   "metadata": {},
   "source": [
    "The corresponding error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leastsqerror(a, xd, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41f4c1",
   "metadata": {},
   "source": [
    "The next polynomial is of degree four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 4)\n",
    "xaxis = np.linspace(1, 6, 500)\n",
    "yvals = poly(xaxis, a)\n",
    "plt.plot(xaxis, yvals)\n",
    "plt.plot(xd, yd, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013cc51",
   "metadata": {},
   "source": [
    "The least squares error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb66ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "leastsqerror(a, xd, yd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c3ba1",
   "metadata": {},
   "source": [
    "Finally, we try a fifth degree polynomial. Recall that the normal\n",
    "equations have a unique solution when $x_i$ are distinct, and\n",
    "$n\\leq m-1$. Since $m=6$ in this example, $n=5$ is the largest\n",
    "degree with guaranteed unique solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = leastsqfit(xd, yd, 5)\n",
    "xaxis = np.linspace(1, 6, 500)\n",
    "yvals = poly(xaxis, a)\n",
    "plt.plot(xaxis, yvals)\n",
    "plt.plot(xd, yd, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325fb1d",
   "metadata": {},
   "source": [
    "The approximating polynomial of degree five is the interpolating\n",
    "polynomial! What is the least squares error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbab47",
   "metadata": {},
   "source": [
    "## Least squares with non-polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c71d0",
   "metadata": {},
   "source": [
    "The method of least squares is not only for polynomials. For example, suppose we want to find the function\n",
    "\n",
    "\\begin{equation}\\label{eq:tempf}\n",
    "f(t)=a+bt+c \\sin(2\\pi t/365)+d \\cos (2\\pi t/365)\n",
    "\\end{equation}\n",
    "\n",
    "that has the best fit to some data $(t_1,T_1),...,(t_m,T_m)$ in the least-squares sense. This function is used in modeling weather temperature data, where $t$ denotes time, and $T$ denotes the temperature. The following figure plots the daily maximum temperature during a period of 1,056 days, from 2016 until November 21, 2018, as measured by a weather station at Melbourne airport, Australia[^1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba3d3b7",
   "metadata": {},
   "source": [
    "<img src=\"./images/tempdata.png\" class=\"bg-primary mb-1\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311440c5",
   "metadata": {},
   "source": [
    "To find the best fit function of the form \\eqref{eq:tempf}, we write the least squares error term\n",
    "\\begin{equation*}\n",
    "E=\\sum_{i=1}^m (f(t_i)-T_i)^2=\\sum_{i=1}^m \\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)^2,\n",
    "\\end{equation*}\n",
    "and set its partial derivatives with respect to the unknowns $a,b,c,d$ to zero to obtain the normal equations:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial a}=0 &\\Rightarrow \\sum_{i=1}^m 2\\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\nonumber  \\\\\n",
    "&\\Rightarrow \\sum_{i=1}^m \\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\label{eq:n1},\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial b}=0 &\\Rightarrow \\sum_{i=1}^m (2t_i)\\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\nonumber  \\\\\n",
    "&\\Rightarrow \\sum_{i=1}^m t_i\\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\label{eq:n2},\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial c}=0 &\\Rightarrow \\sum_{i=1}^m \\left(2\\sin\\left(\\frac{2\\pi t_i}{365}\\right)\\right)\\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\nonumber  \\\\\n",
    "&\\Rightarrow \\sum_{i=1}^m \\sin\\left(\\frac{2\\pi t_i}{365}\\right) \\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\label{eq:n3},\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial E}{\\partial d}=0 &\\Rightarrow \\sum_{i=1}^m \\left(2\\cos\\left(\\frac{2\\pi t_i}{365}\\right)\\right)\\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\nonumber  \\\\\n",
    "&\\Rightarrow \\sum_{i=1}^m \\cos\\left(\\frac{2\\pi t_i}{365}\\right) \\left(a+bt_i+c \\sin\\left(\\frac{2\\pi t_i}{365}\\right)+d \\cos \\left(\\frac{2\\pi t_i}{365}\\right)-T_i\\right)=0\\label{eq:n4}.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Rearranging terms in equations \\eqref{eq:n1}, \\eqref{eq:n2}, \\eqref{eq:n3}, \\eqref{eq:n4}, we get a system of four equations and four unknowns:\n",
    "\n",
    "\\begin{align*}\n",
    "&am+b \\sum_{i=1}^m t_i + c \\sum_{i=1}^m \\sin\\left(\\frac{2\\pi t_i}{365}\\right) + d \\sum_{i=1}^m \\cos \\left(\\frac{2\\pi t_i}{365}\\right)=\\sum_{i=1}^m T_i\\\\\n",
    "&a \\sum_{i=1}^m t_i + b\\sum_{i=1}^m t_i^2 + c\\sum_{i=1}^m t_i \\sin \\left(\\frac{2\\pi t_i}{365}\\right) + d \\sum_{i=1}^m t_i \\cos \\left(\\frac{2\\pi t_i}{365}\\right) = \\sum_{i=1}^m T_i t_i\\\\\n",
    "&a \\sum_{i=1}^m \\sin\\left(\\frac{2\\pi t_i}{365}\\right) + b \\sum_{i=1}^m t_i \\sin \\left(\\frac{2\\pi t_i}{365}\\right) +c \\sum_{i=1}^m \\sin^2 \\left(\\frac{2\\pi t_i}{365}\\right) + d \\sum_{i=1}^m \\sin \\left(\\frac{2\\pi t_i}{365}\\right) \\cos \\left(\\frac{2\\pi t_i}{365}\\right)\\\\\n",
    "&= \\sum_{i=1}^m T_i \\sin \\left(\\frac{2\\pi t_i}{365}\\right)\\\\\n",
    "&a \\sum_{i=1}^m \\cos\\left(\\frac{2\\pi t_i}{365}\\right) +  b \\sum_{i=1}^m t_i \\cos \\left(\\frac{2\\pi t_i}{365}\\right) + c \\sum_{i=1}^m \\sin \\left(\\frac{2\\pi t_i}{365}\\right) \\cos \\left(\\frac{2\\pi t_i}{365}\\right) + d \\sum_{i=1}^m \\cos^2 \\left(\\frac{2\\pi t_i}{365}\\right)\\\\\n",
    "&= \\sum_{i=1}^m T_i \\cos \\left(\\frac{2\\pi t_i}{365}\\right)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Using a short-hand notation where we suppress the argument $\\left(\\frac{2\\pi t_i}{365}\\right)$ in the trigonometric functions, and the summation indices, we write the above equations as a matrix equation:\n",
    "\\begin{equation*}\n",
    "\\underbrace{\n",
    "\\begin{bmatrix}\n",
    "m &  \\sum t_i & \\sum \\sin(\\cdot) & \\sum \\cos(\\cdot) \\\\\n",
    " \\sum t_i&  \\sum t_i^2&  \\sum t_i \\sin(\\cdot) & \\sum t_i \\cos(\\cdot)\\\\\n",
    " \\sum \\sin(\\cdot)& \\sum t_i \\sin(\\cdot)& \\sum \\sin^2(\\cdot)& \\sum \\sin(\\cdot) \\cos(\\cdot) \\\\\n",
    " \\sum \\cos(\\cdot) & \\sum t_i \\cos(\\cdot) & \\sum \\sin(\\cdot) \\cos(\\cdot)& \\sum \\cos^2(\\cdot)\n",
    "\\end{bmatrix}}_{\\mathbf{A}}\n",
    "\\begin{bmatrix}\n",
    "a\\\\\n",
    "b\\\\\n",
    "c\\\\\n",
    "d\n",
    "\\end{bmatrix}=\n",
    "\\underbrace{\n",
    "\\begin{bmatrix}\n",
    "\\sum T_i\\\\\n",
    "\\sum T_i t_i\\\\\n",
    "\\sum T_i \\sin(\\cdot)\\\\\n",
    "\\sum T_i \\cos(\\cdot)\n",
    "\\end{bmatrix}}_{\\mathbf{r}}\n",
    "\\end{equation*}\n",
    "Next, we will use Python to load the data and define the matrices $A, \\mathbf{r}$, and then solve the equation $A\\mathbf{x}=\\mathbf{r}$, where $\\mathbf{x}=[a,b,c,d]^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd02fce8",
   "metadata": {},
   "source": [
    "We will use a package called pandas to import data. We import it in our notebook, along with NumPy and Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf4ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ccbe21",
   "metadata": {},
   "source": [
    "We assume that the data which consists of temperatures is downloaded as\n",
    "a csv file in the same directory where the Python notebook is stored.\n",
    "Make sure the data has no missing entries. The function **pd.read_csv** imports the data into Python as a table (dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WeatherData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a06e57a",
   "metadata": {},
   "source": [
    "The next step is to store the part of the data we need as an array. In our table there is only one column named **Temp**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df['Temp'].to_numpy()\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9845b7b",
   "metadata": {},
   "source": [
    "Let's check the type of **temp**, its first entry, and its length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac8188",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b9584",
   "metadata": {},
   "source": [
    "There are 1,056 temperature values. The $x$-coordinates are the days,\n",
    "numbered $t=1,2,...,1056$. Here is the array that stores these time\n",
    "values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b35fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(1, 1057)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37076646",
   "metadata": {},
   "source": [
    "Next we define the matrix $A$, taking advantage of the fact that\n",
    "the matrix is symmetric. The function **np.sum(x)** adds the entries of the array **x**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((4,4))\n",
    "A[0,0] = 1056\n",
    "A[0,1] = np.sum(time)\n",
    "A[0,2] = np.sum(np.sin(2*np.pi*time/365))\n",
    "A[0,3] = np.sum(np.cos(2*np.pi*time/365))\n",
    "A[1,1] = np.sum(time**2)\n",
    "A[1,2] = np.sum(time*np.sin(2*np.pi*time/365))\n",
    "A[1,3] = np.sum(time*np.cos(2*np.pi*time/365))\n",
    "A[2,2] = np.sum(np.sin(2*np.pi*time/365)**2)\n",
    "A[2,3] = np.sum(np.sin(2*np.pi*time/365)*np.cos(2*np.pi*time/365))\n",
    "A[3,3] = np.sum(np.cos(2*np.pi*time/365)**2)\n",
    "for i in range(1,4):\n",
    "    for j in range(i):\n",
    "        A[i,j] = A[j,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c632844",
   "metadata": {},
   "source": [
    "Now we define the vector **r**. The function **np.dot(x,y)** takes the dot product of the arrays $x,y$. For example, **np.dot**$([1,2,3],[4,5,6])=1\\times 4+2\\times 5+ 3\\times 6 = 32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab3a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(4)\n",
    "r[0] = np.sum(temp)\n",
    "r[1] = np.dot(temp, time)\n",
    "r[2] = np.dot(temp, np.sin(2*np.pi*time/365))\n",
    "r[3] = np.dot(temp, np.cos(2*np.pi*time/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba459d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2132b34b",
   "metadata": {},
   "source": [
    "We can solve the matrix equation now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(A, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369176c6",
   "metadata": {},
   "source": [
    "Recall that these constants are the values of $a,b,c,d$ in the\n",
    "definition of $f(t)$. Here is the best fitting function to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda t: 20.2898 + 0.00116773*t + 2.72116*np.sin(2*np.pi*t/365) + \\\n",
    "6.88809*np.cos(2*np.pi*t/365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05b6ba",
   "metadata": {},
   "source": [
    "We next plot the data together with $f(t)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c025e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.arange(1, 1057)\n",
    "yvals = f(xaxis)\n",
    "plt.plot(xaxis, yvals, label='Least squares approximation')\n",
    "plt.xlabel('time (t)')\n",
    "plt.ylabel('Temperature (T)')\n",
    "plt.plot(temp, linestyle='-', alpha=0.5, label='Data')\n",
    "plt.legend(loc='upper center');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56adc616",
   "metadata": {},
   "source": [
    "## Linearizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216d6f3",
   "metadata": {},
   "source": [
    "For another example of non-polynomial least squares, consider finding the\n",
    "function $f(x)=be^{ax}$ with the best least squares fit to some data $(x_{1},y_{1}),(x_{2},y_{2}),...,(x_{m},y_{m})$.\n",
    "We need to find $a,b$ that minimize\n",
    "\\begin{equation*}\n",
    "E=\\sum_{i=1}^{m}(y_{i}-be^{ax_{i}})^{2}.\n",
    "\\end{equation*}\n",
    "The normal equations are\n",
    "\\begin{equation*}\n",
    "\\frac{\\partial E}{\\partial a}=0\\text{ and }\\frac{\\partial E}{\\partial b}=0;\n",
    "\\end{equation*}\n",
    "however, unlike the previous example, this is not a system of linear equations in the unknowns $a,b$. In general, a root finding type method is needed to solve these equations.\n",
    "\n",
    "There is a simpler approach we can use when we suspect the data is\n",
    "exponentially related. Consider again the function we want to fit:\n",
    "\n",
    "\\begin{equation}\\label{eq:exp_fit}\n",
    "y=be^{ax}.\n",
    "\\end{equation}\n",
    "\n",
    "Take the logarithm of both sides:\n",
    "\\begin{equation*}\n",
    "\\log y=\\log b+ax\n",
    "\\end{equation*}\n",
    "and rename the variables as $Y=\\log y,B=\\log b$. Then we obtain the\n",
    "expression\n",
    "\n",
    "\\begin{equation}\\label{eq:lin_fit}\n",
    "Y=ax+B\n",
    "\\end{equation}\n",
    "\n",
    "which is a linear equation in the transformed variable. In other words,\n",
    "if the original variable $y$ is related to $x$ via Equation \\eqref{eq:exp_fit},\n",
    "then $Y=\\log y$ is related to $x$ via a linear relationship given\n",
    "by Equation \\eqref{eq:lin_fit}. So, the new approach is to fit the\n",
    "least squares line $Y=ax+B$ to the data\n",
    "\\begin{equation*}\n",
    "(x_{1},\\log y_{1}),(x_{2},\\log y_{2}),...,(x_{m},\\log y_{m}).\n",
    "\\end{equation*}\n",
    "\n",
    "However, it is important to realize that the least squares fit to\n",
    "the transformed data is not necessarily the same as the least squares\n",
    "fit to the original data. The reason is the deviations which least\n",
    "squares minimize are distorted in a non-linear way by the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7d909",
   "metadata": {},
   "source": [
    "\\begin{example}\\label{example:chap5_exa85}\n",
    "Consider the following data\n",
    "\n",
    "|$x$ | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "|:---|:---|:---|:---|:---|:---|:---|\n",
    "|$y$ | 3 | 5 | 8| 12 | 23 | 37 |\n",
    "\n",
    "to which we will fit $y=be^{ax}$ in the least-squares sense. The following table displays the data $(x_i,\\log y_i)$, using two-digits:\n",
    "\n",
    "|$x$ | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "|:---|:---|:---|:---|:---|:---|:---|\n",
    "|$Y=\\log y$ | 1.1 | 1.6 | 2.1 | 2.5 | 3.1 | 3.6 |\n",
    "\\end{example}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbefc62",
   "metadata": {},
   "source": [
    "We use the Python code **leastsqfit** to fit a line to this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2, 3, 4, 5])\n",
    "y = np.array([1.1, 1.6, 2.1, 2.5, 3.1, 3.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "leastsqfit(x, y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35708a",
   "metadata": {},
   "source": [
    "Therefore the least squares line, using two-digits, is\n",
    "\\begin{equation*}\n",
    "Y=0.5x+1.1.\n",
    "\\end{equation*}\n",
    "This equation corresponds to Equation \\eqref{eq:lin_fit}, with $a=0.5$ and $B=1.1$. We want to obtain the corresponding exponential Equation \\eqref{eq:exp_fit}, where $b=e^B$. Since $e^{1.1}=3$, the best fitting exponential function to the data is $y=3e^{x/2}$. The following graph plots $y=3e^{x/2}$ together with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf05a373",
   "metadata": {},
   "source": [
    "<img src=\"./images/expdata_exp.png\" class=\"bg-primary mb-1\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392b190",
   "metadata": {},
   "source": [
    "**Exercise 6.1-1**\n",
    "\n",
    "Find the function of the form $y=ae^x+b \\sin (4 x)$ that best fits the data below in the least squares sense.\n",
    "\n",
    "|$x$ | 1 | 2 | 3 | 4 | 5 |\n",
    "|:---|:---|:---|:---|:---|:---|\n",
    "|$y$ | -4 | 6 | -1 | 5 | 20 |\n",
    "\n",
    "Plot the function and the data together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c51d97c",
   "metadata": {},
   "source": [
    "**Exercise 6.1-2**\n",
    "\n",
    "Power-law type relationships are observed in many empirical data. Two variables $y$, $x$ are said to be related via a power-law if $y=kx^\\alpha$, where $k,\\alpha$ are some constants. The following data[^2] lists the top 10 family names in the order of occurrence according to Census 2000. Investigate whether relative frequency of occurrences and the rank of the name are related via a power-law, by\n",
    "\n",
    "a) Let $y$ be the relative frequencies (number of occurrences divided by the total number of occurrences), and $x$ be the rank, that is, 1 through 10.\n",
    "\n",
    "b) Use least squares to find a function of the form $y=kx^\\alpha$. Use linearization.\n",
    "\n",
    "c) Plot the data together with the best fitting function found in part (b).\n",
    "\n",
    "|Name | Number of Occurrences|\n",
    "|:---|:---|\n",
    "|Smith | 2,376,206|\n",
    "|Johnson | 1,857,160|\n",
    "|Williams | 1,534,042|\n",
    "|Brown | 1,380,145|\n",
    "|Jones | 1,362,755|\n",
    "|Miller | 1,127,803|\n",
    "|Davis | 1,072,335|\n",
    "|Garcia | 858,289|\n",
    "|Rodriguez | 804,240|\n",
    "|Wilson | 783,051|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a99b9",
   "metadata": {},
   "source": [
    "[^1]: https://www.census.gov/topics/population/genealogy/data/2000\\_surnames.html\n",
    "\n",
    "[^2]: http://www.bom.gov.au/climate/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5e897",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b96f1",
   "metadata": {},
   "source": [
    "M.T. Heath. Scientific Computing: An introductory survey. McGraw-Hill, 1997."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
